Parfait ! ğŸ¯ Je vais crÃ©er un rapport simplifiÃ© et clair avec seulement les informations essentielles.
ğŸ“Š Version SimplifiÃ©e du Rapport
CrÃ©ez simple_report_manager.py :
"""
simple_report_manager.py
Rapport simplifiÃ© avec informations essentielles uniquement
"""

from datetime import datetime
from pyspark.sql import functions as F


class SimpleReportManager:
    """Gestionnaire de rapport simplifiÃ© et lisible"""
    
    def __init__(self, spark, config):
        self.spark = spark
        self.config = config
        self.execution_start = datetime.now()
    
    def generate_simple_report(self, total_files_processed: int, total_failed: int,
                               execution_time: float):
        """
        GÃ©nÃ¨re un rapport simple et clair
        
        Args:
            total_files_processed: Nombre de fichiers rÃ©ussis
            total_failed: Nombre de fichiers Ã©chouÃ©s
            execution_time: DurÃ©e totale en secondes
        """
        
        print("\n" + "=" * 100)
        print("ğŸ“Š RAPPORT D'EXÃ‰CUTION WAX PIPELINE")
        print("=" * 100)
        
        # ========== 1. RÃ‰SUMÃ‰ EXÃ‰CUTION ==========
        self._print_execution_summary(total_files_processed, total_failed, execution_time)
        
        # ========== 2. FICHIERS RÃ‰USSIS ==========
        self._print_successful_files()
        
        # ========== 3. FICHIERS REJETÃ‰S ==========
        self._print_rejected_files()
        
        # ========== 4. TABLES CRÃ‰Ã‰ES ==========
        self._print_created_tables()
        
        # ========== 5. ALERTES ==========
        self._print_alerts()
        
        print("\n" + "=" * 100)
        print("âœ… Rapport terminÃ©")
        print("=" * 100 + "\n")
    
    def _print_execution_summary(self, total_success: int, total_failed: int, 
                                 execution_time: float):
        """RÃ©sumÃ© de l'exÃ©cution"""
        
        total_files = total_success + total_failed
        success_rate = (total_success / total_files * 100) if total_files > 0 else 0
        
        # IcÃ´ne selon taux de succÃ¨s
        if success_rate == 100:
            status_icon = "âœ…"
            status_text = "SUCCÃˆS COMPLET"
        elif success_rate >= 75:
            status_icon = "âš ï¸"
            status_text = "SUCCÃˆS PARTIEL"
        else:
            status_icon = "âŒ"
            status_text = "Ã‰CHEC PARTIEL"
        
        print(f"""
{status_icon} STATUT : {status_text}

ğŸ“… Date      : {self.execution_start.strftime('%Y-%m-%d %H:%M:%S')}
â±ï¸  DurÃ©e     : {execution_time:.1f}s ({execution_time/60:.1f} min)
ğŸŒ Environnement : {self.config.env.upper()}

ğŸ“Š RÃ‰SULTAT :
   âœ… Fichiers rÃ©ussis  : {total_success}
   âŒ Fichiers rejetÃ©s  : {total_failed}
   ğŸ“ˆ Taux de succÃ¨s    : {success_rate:.0f}%
        """)
    
    def _print_successful_files(self):
        """Liste des fichiers traitÃ©s avec succÃ¨s"""
        
        print("\n" + "-" * 100)
        print("âœ… FICHIERS TRAITÃ‰S AVEC SUCCÃˆS")
        print("-" * 100)
        
        try:
            exec_table = f"{self.config.catalog}.{self.config.schema_tables}.wax_execution_logs"
            
            if not self._table_exists(exec_table):
                print("   â„¹ï¸  Aucune donnÃ©e disponible")
                return
            
            # Fichiers rÃ©ussis du jour
            successful_df = self.spark.table(exec_table).filter(
                (F.to_date(F.col("log_ts")) == F.current_date()) &
                (F.col("status") == "SUCCESS")
            )
            
            count = successful_df.count()
            
            if count == 0:
                print("   â„¹ï¸  Aucun fichier traitÃ© avec succÃ¨s")
                return
            
            # Afficher les fichiers
            files = successful_df.select(
                F.col("table_name").alias("Table"),
                F.col("filename").alias("Fichier"),
                F.col("row_count").alias("Lignes"),
                F.round(F.col("duration"), 1).alias("DurÃ©e (s)"),
                F.date_format(F.col("log_ts"), "HH:mm:ss").alias("Heure")
            ).orderBy("log_ts").collect()
            
            print(f"\n   ğŸ“ {count} fichier(s) traitÃ©(s) avec succÃ¨s:\n")
            
            for idx, file in enumerate(files, 1):
                print(f"   {idx}. {file.Fichier}")
                print(f"      â€¢ Table      : {file.Table}")
                print(f"      â€¢ Lignes     : {file.Lignes:,}")
                print(f"      â€¢ DurÃ©e      : {file['DurÃ©e (s)']}s")
                print(f"      â€¢ Heure      : {file.Heure}")
                print()
            
            # Total lignes traitÃ©es
            total_rows = sum(f.Lignes for f in files)
            print(f"   ğŸ“Š Total : {total_rows:,} lignes traitÃ©es avec succÃ¨s")
            
        except Exception as e:
            print(f"   âš ï¸  Erreur : {e}")
    
    def _print_rejected_files(self):
        """Liste des fichiers rejetÃ©s avec raisons"""
        
        print("\n" + "-" * 100)
        print("âŒ FICHIERS REJETÃ‰S")
        print("-" * 100)
        
        try:
            exec_table = f"{self.config.catalog}.{self.config.schema_tables}.wax_execution_logs"
            
            if not self._table_exists(exec_table):
                print("   â„¹ï¸  Aucune donnÃ©e disponible")
                return
            
            # Fichiers Ã©chouÃ©s du jour
            failed_df = self.spark.table(exec_table).filter(
                (F.to_date(F.col("log_ts")) == F.current_date()) &
                (F.col("status") == "FAILED")
            )
            
            count = failed_df.count()
            
            if count == 0:
                print("   âœ… Aucun fichier rejetÃ©")
                return
            
            # Afficher les fichiers rejetÃ©s
            files = failed_df.select(
                F.col("table_name").alias("Table"),
                F.col("filename").alias("Fichier"),
                F.col("error_message").alias("Raison"),
                F.date_format(F.col("log_ts"), "HH:mm:ss").alias("Heure")
            ).orderBy("log_ts").collect()
            
            print(f"\n   ğŸš« {count} fichier(s) rejetÃ©(s):\n")
            
            for idx, file in enumerate(files, 1):
                print(f"   {idx}. {file.Fichier}")
                print(f"      â€¢ Table      : {file.Table}")
                print(f"      â€¢ Raison     : {file.Raison}")
                print(f"      â€¢ Heure      : {file.Heure}")
                print()
            
        except Exception as e:
            print(f"   âš ï¸  Erreur : {e}")
    
    def _print_created_tables(self):
        """Tables crÃ©Ã©es avec leurs statistiques"""
        
        print("\n" + "-" * 100)
        print("ğŸ—„ï¸  TABLES CRÃ‰Ã‰ES")
        print("-" * 100)
        
        try:
            # Lister tables WAX
            tables = self.spark.sql(
                f"SHOW TABLES IN {self.config.catalog}.{self.config.schema_tables}"
            ).collect()
            
            wax_tables = [t for t in tables if "_all" in t.tableName or "_last" in t.tableName]
            
            if not wax_tables:
                print("   â„¹ï¸  Aucune table crÃ©Ã©e")
                return
            
            # Grouper par base (table_all et table_last ensemble)
            table_groups = {}
            for table in wax_tables:
                base_name = table.tableName.replace("_all", "").replace("_last", "")
                if base_name not in table_groups:
                    table_groups[base_name] = []
                table_groups[base_name].append(table.tableName)
            
            print(f"\n   ğŸ“Š {len(table_groups)} table(s) crÃ©Ã©e(s):\n")
            
            for idx, (base_name, table_list) in enumerate(table_groups.items(), 1):
                print(f"   {idx}. {base_name.upper()}")
                
                for table_name in sorted(table_list):
                    table_full = f"{self.config.catalog}.{self.config.schema_tables}.{table_name}"
                    
                    try:
                        df = self.spark.table(table_full)
                        count = df.count()
                        
                        # RÃ©cupÃ©rer nombre de fichiers sources
                        sources_count = 0
                        if "FILE_NAME_RECEIVED" in df.columns:
                            sources_count = df.select("FILE_NAME_RECEIVED").distinct().count()
                        
                        # Type de table
                        if "_all" in table_name:
                            table_type = "Historique"
                        else:
                            table_type = "Courante"
                        
                        print(f"      â€¢ {table_name}")
                        print(f"        - Type        : {table_type}")
                        print(f"        - Lignes      : {count:,}")
                        if sources_count > 0:
                            print(f"        - Fichiers    : {sources_count}")
                    
                    except Exception as e:
                        print(f"      â€¢ {table_name} : Erreur lecture")
                
                print()
            
        except Exception as e:
            print(f"   âš ï¸  Erreur : {e}")
    
    def _print_alerts(self):
        """Alertes et points d'attention"""
        
        print("\n" + "-" * 100)
        print("âš ï¸  ALERTES ET POINTS D'ATTENTION")
        print("-" * 100)
        
        alerts = []
        
        # VÃ©rifier erreurs qualitÃ©
        try:
            quality_table = f"{self.config.catalog}.{self.config.schema_tables}.wax_data_quality_errors"
            
            if self._table_exists(quality_table):
                errors_df = self.spark.table(quality_table).filter(
                    F.to_date(F.col("log_ts")) == F.current_date()
                )
                
                error_count = errors_df.count()
                
                if error_count > 0:
                    # Top 3 erreurs
                    top_errors = errors_df.groupBy("error_message").agg(
                        F.sum(F.col("error_count").cast("bigint")).alias("total")
                    ).orderBy(F.desc("total")).limit(3).collect()
                    
                    alerts.append({
                        "type": "QUALITÃ‰",
                        "severity": "warning" if error_count < 100 else "critical",
                        "message": f"{error_count} erreur(s) de qualitÃ© dÃ©tectÃ©e(s)",
                        "details": [f"{row.error_message}: {row.total}" for row in top_errors]
                    })
        except:
            pass
        
        # VÃ©rifier performance
        try:
            exec_table = f"{self.config.catalog}.{self.config.schema_tables}.wax_execution_logs"
            
            if self._table_exists(exec_table):
                slow_files = self.spark.table(exec_table).filter(
                    (F.to_date(F.col("log_ts")) == F.current_date()) &
                    (F.col("status") == "SUCCESS") &
                    (F.col("duration") > 60)  # Plus de 60 secondes
                )
                
                slow_count = slow_files.count()
                
                if slow_count > 0:
                    alerts.append({
                        "type": "PERFORMANCE",
                        "severity": "info",
                        "message": f"{slow_count} fichier(s) lent(s) (>60s)",
                        "details": []
                    })
        except:
            pass
        
        # Afficher alertes
        if not alerts:
            print("\n   âœ… Aucune alerte - ExÃ©cution parfaite !")
            return
        
        print(f"\n   ğŸ“‹ {len(alerts)} alerte(s) dÃ©tectÃ©e(s):\n")
        
        for idx, alert in enumerate(alerts, 1):
            # IcÃ´ne selon sÃ©vÃ©ritÃ©
            if alert["severity"] == "critical":
                icon = "ğŸ”´"
            elif alert["severity"] == "warning":
                icon = "ğŸŸ "
            else:
                icon = "ğŸ”µ"
            
            print(f"   {idx}. {icon} [{alert['type']}] {alert['message']}")
            
            for detail in alert["details"]:
                print(f"      â€¢ {detail}")
            print()
    
    def _table_exists(self, table_name: str) -> bool:
        """VÃ©rifie si une table existe"""
        try:
            self.spark.table(table_name)
            return True
        except:
            return False
ğŸ“ Simplification de print_summary() dans logger_manager.py
Remplacez aussi la fonction print_summary() par une version minimaliste :
def print_summary(self, table_name: str, filename: str, total_rows,
                  corrupt_rows: int, anomalies_total: int, cleaned_rows: int,
                  errors_df: DataFrame):
    """RÃ©sumÃ© minimaliste par fichier"""
    
    # Une ligne par fichier
    if isinstance(total_rows, tuple):
        rows_str = f"{total_rows[1]:,}"
    else:
        rows_str = f"{total_rows:,}"
    
    status_icon = "âœ…" if anomalies_total == 0 else "âš ï¸"
    
    print(f"{status_icon} {filename:<45} | Lignes: {rows_str:>10} | Erreurs: {anomalies_total:>4}")
ğŸ”§ IntÃ©gration dans main.py
Remplacez la section rapport Ã  la fin de main.py :
def main():
    """Point d'entrÃ©e pipeline"""
    
    start_total_time = time.time()  # Au dÃ©but
    
    # ... tout le code existant ...
    
    # ========== RÃ‰SUMÃ‰ FINAL SIMPLIFIÃ‰ ==========
    
    execution_time = time.time() - start_total_time
    
    # Rapport simplifiÃ©
    if total_files_processed > 0 or total_failed > 0:
        try:
            from simple_report_manager import SimpleReportManager
            
            report_manager = SimpleReportManager(spark, config)
            report_manager.generate_simple_report(
                total_files_processed=total_files_processed,
                total_failed=total_failed,
                execution_time=execution_time
            )
            
        except Exception as e:
            print(f"âš ï¸ Erreur gÃ©nÃ©ration rapport : {e}")
            import traceback
            traceback.print_exc()
    
    print("\nğŸ¯ Pipeline terminÃ© !")


if __name__ == "__main__":
    main()
ğŸ“Š Exemple de Rapport GÃ©nÃ©rÃ©
====================================================================================================
ğŸ“Š RAPPORT D'EXÃ‰CUTION WAX PIPELINE
====================================================================================================

âœ… STATUT : SUCCÃˆS PARTIEL

ğŸ“… Date      : 2025-10-14 15:30:00
â±ï¸  DurÃ©e     : 67.3s (1.1 min)
ğŸŒ Environnement : DEV

ğŸ“Š RÃ‰SULTAT :
   âœ… Fichiers rÃ©ussis  : 2
   âŒ Fichiers rejetÃ©s  : 1
   ğŸ“ˆ Taux de succÃ¨s    : 67%

----------------------------------------------------------------------------------------------------
âœ… FICHIERS TRAITÃ‰S AVEC SUCCÃˆS
----------------------------------------------------------------------------------------------------

   ğŸ“ 2 fichier(s) traitÃ©(s) avec succÃ¨s:

   1. site_20250902_120001.csv
      â€¢ Table      : site
      â€¢ Lignes     : 105,628
      â€¢ DurÃ©e      : 32.5s
      â€¢ Heure      : 15:30:00

   2. site_20250906_120001.csv
      â€¢ Table      : site
      â€¢ Lignes     : 105,628
      â€¢ DurÃ©e      : 33.2s
      â€¢ Heure      : 15:30:35

   ğŸ“Š Total : 211,256 lignes traitÃ©es avec succÃ¨s

----------------------------------------------------------------------------------------------------
âŒ FICHIERS REJETÃ‰S
----------------------------------------------------------------------------------------------------

   ğŸš« 1 fichier(s) rejetÃ©(s):

   1. site_20251302_120001.csv
      â€¢ Table      : site
      â€¢ Raison     : Invalid date: Month 13
      â€¢ Heure      : 15:31:00

----------------------------------------------------------------------------------------------------
ğŸ—„ï¸  TABLES CRÃ‰Ã‰ES
----------------------------------------------------------------------------------------------------

   ğŸ“Š 1 table(s) crÃ©Ã©e(s):

   1. SITE
      â€¢ site_all
        - Type        : Historique
        - Lignes      : 211,256
        - Fichiers    : 2
      â€¢ site_last
        - Type        : Courante
        - Lignes      : 105,628
        - Fichiers    : 1

----------------------------------------------------------------------------------------------------
âš ï¸  ALERTES ET POINTS D'ATTENTION
----------------------------------------------------------------------------------------------------

   âœ… Aucune alerte - ExÃ©cution parfaite !

====================================================================================================
âœ… Rapport terminÃ©
====================================================================================================
âœ… Avantages du Rapport SimplifiÃ©
Aspect
Avant
AprÃ¨s
Longueur
~500 lignes
~50 lignes
Sections
7 sections
5 sections essentielles
DÃ©tails
TrÃ¨s technique
Informations clÃ©s
LisibilitÃ©
Pour dÃ©veloppeurs
Pour tous
Focus
Tout
RÃ©ussis + RejetÃ©s
Temps lecture
5-10 min
1-2 min
ğŸ¯ Ce qui est conservÃ© (Essentiel)
âœ… Statut global (succÃ¨s/Ã©chec)
âœ… DurÃ©e d'exÃ©cution
âœ… Liste fichiers rÃ©ussis avec dÃ©tails
âœ… Liste fichiers rejetÃ©s avec raisons
âœ… Tables crÃ©Ã©es
âœ… Alertes importantes
ğŸ—‘ï¸ Ce qui est enlevÃ© (Superflu)
âŒ Statistiques dÃ©taillÃ©es
âŒ Performance par table
âŒ Top erreurs exhaustif
âŒ Recommandations longues
âŒ MÃ©triques techniques
Testez et dites-moi si c'est assez clair ! ğŸš€
